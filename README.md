# Austin-Housing-Price-Prediction
Machine Learning Prediction Contest entry for Austin housing prices. 

Goal:
In this prediction contest, we aimed to build our best predictive model for housing prices in the Austin housing dataset based on the variables provided. The goal was to create the most accurate predictions for house prices for the holdout set using a model described in the course.

Data Preparation & Feature Engineering:
Within the dataset of over 13,000 listings, there were several variables that weren’t necessary or useful in our model. Variables such as streetAddress and description were removed as these strings as a whole weren’t useful in making predictions. homeType was also converted to a factor, which was also later dropped since all listings are single family units. We converted latest_saledate to a date object to simplify our later calculations before discarding the original date column. To ensure the zipcode was accurately modeled as a factor variable, we created a factor variable with levels being the first 4 digits of the zipcode so that it could be used across all models. Additionally, we added features in an attempt to improve the model’s accuracy. Instead of having longitude and latitude as direct predictors, we computed the distance of the homes from downtown Austin using the Haversine distance formula as we figured this would likely have a greater impact on house price. The predictors numOfAccessibilityFeatures, numOfPatioAndPorchFeatures, numOfSecurityFeatures, numOfWaterfrontFeatures, numOfWindowFeatures, and numOfCommunityFeatures had low counts and limited variation, so we combined them into a single aggregate feature called numOfUniqueFeatures. We took a similar approach by combining the presence of amenities (association, garage, spa, view) into a single variable, numOfAmenities. Finally, we computed daysSinceLastSale to replace all of the latest sale related predictors and simplify calculation and interpretation. Other variables including numOfAppliances and numOfPhotos were also removed as these ended up increasing our test RMSE calculations as we modeled the data.

Model Selection and Evaluation:
We evaluated the following models using RMSE on a validation set: stepwise regression, lasso, ridge regression, decision trees (including pruning), bagging, random forests, boosting and BART. The best results came from Bayesian Additive Regression Trees (BART), which had the lowest RMSE of 151.2 so we proceeded with that and used it to generate the predicted prices for the holdout set.
